{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(2.0,requires_grad=True)\n",
    "b = torch.tensor(-1.0,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    yhat = w*x+b\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1.0]])\n",
    "y_hat = forward(x)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor([[2.0],[1.6]])\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0000],\n",
       "        [2.2000]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here x has multiple values, so yhat is performed twice,\n",
    "#each time using individual value of x\n",
    "yhat = forward(x1)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x113bead70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the linear class can be used to make the prediciton \n",
    "from torch.nn import Linear\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters w and b:[Parameter containing:\n",
      "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4414], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "#create a linear regression model\n",
    "lr = Linear(in_features=1,out_features=1,bias=True)\n",
    "print(f\"Parameters w and b:{list(lr.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python dictionary: OrderedDict([('weight', tensor([[0.5153]])), ('bias', tensor([-0.4414]))])\n",
      "keys: odict_keys(['weight', 'bias'])\n",
      "Values: odict_values([tensor([[0.5153]]), tensor([-0.4414])])\n"
     ]
    }
   ],
   "source": [
    "#state_dict() returns each parameter ie, w and b in each layer\n",
    "print(\"Python dictionary:\",lr.state_dict())\n",
    "print(\"keys:\",lr.state_dict().keys())\n",
    "print(\"Values:\",lr.state_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: Parameter containing:\n",
      "tensor([[0.5153]], requires_grad=True)\n",
      "Bias: Parameter containing:\n",
      "tensor([-0.4414], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Weight:\",lr.weight)\n",
    "print(\"Bias:\",lr.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0739]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1.0]])\n",
    "yhat = lr(x)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3315],\n",
       "        [1.6712],\n",
       "        [2.6502]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the prediction for multiple input using Linear model\n",
    "#note: don't be confused by in_features=1, here, each row has 1 parameter, ie, one input feature on each row\n",
    "x1 = torch.tensor([[1.5],[4.1],[6.0]])\n",
    "yhat = lr(x1)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make custom modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customize linear regression class\n",
    "class LR(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        #Inherit from parent\n",
    "        super(LR,self).__init__()\n",
    "        #create a forward formula: wx+b with fixed input and output size\n",
    "        self.linear = nn.Linear(input_size,output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters:w and b [Parameter containing:\n",
      "tensor([[0.3652]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3897], requires_grad=True)]\n",
      "Dictionary OrderedDict([('linear.weight', tensor([[0.3652]])), ('linear.bias', tensor([-0.3897]))])\n",
      "keys odict_keys(['linear.weight', 'linear.bias'])\n",
      "values odict_values([tensor([[0.3652]]), tensor([-0.3897])])\n"
     ]
    }
   ],
   "source": [
    "lr = LR(1,1)\n",
    "print(\"parameters:w and b\",list(lr.parameters()))\n",
    "print(\"Dictionary\",lr.state_dict())\n",
    "print(\"keys\",lr.state_dict().keys())\n",
    "print(\"values\",lr.state_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
